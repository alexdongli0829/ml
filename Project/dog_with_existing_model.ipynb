{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second project with pretrained model to train for the dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import gluonbook as gb\n",
    "import math\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import os\n",
    "import shutil\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extractall the files\n",
    "demo=False\n",
    "data_dir = \"../../data/kaggle_dog/\"\n",
    "\n",
    "if demo:\n",
    "    zipfiles = [\"train_valid_test_tiny.zip\"]\n",
    "else:\n",
    "    zipfiles = [\"test.zip\",\"train.zip\", \"labels.csv.zip\"]\n",
    "if not os.path.exists(data_dir+\"train\") or demo:\n",
    "    for f in zipfiles:\n",
    "        with zipfile.ZipFile(data_dir+f, 'r') as z:\n",
    "            z.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orgnize the data for the later load\n",
    "def regor_dog_data(data_dir, train_data, test_data, label_data, input_dir, valid_rate):\n",
    "    # open the label file and find out the least train dogs sample number\n",
    "    with open(data_dir+label_data, 'r') as f:\n",
    "        lines=f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(\",\") for l in lines]\n",
    "        idx_label=dict((idx, label) for idx, label in tokens)\n",
    "    \n",
    "    \n",
    "    def mkdir_if_not_exist(path):\n",
    "        if not os.path.exists(os.path.join(*path)):\n",
    "            os.makedirs(os.path.join(*path))\n",
    "        \n",
    "    minmum_dog_number = (collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
    "    #mkdir for each label in train and valid folder, copy the files into each label folder\n",
    "    # put the test data into input test folder with unknow label\n",
    "    valid_sample_number = math.floor(minmum_dog_number*valid_rate)\n",
    "    copy_dict={}\n",
    "    \n",
    "    \n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_data)):\n",
    "        idx = train_file.split(\".\")[0]\n",
    "        label =idx_label[idx]\n",
    "        mkdir_if_not_exist([data_dir, input_dir, \"train_valid\", label])\n",
    "        shutil.copy(os.path.join(data_dir, train_data,train_file), os.path.join(data_dir, input_dir,\"train_valid\", label))\n",
    "        if label not in copy_dict or copy_dict[label] < valid_sample_number:\n",
    "            mkdir_if_not_exist([data_dir, input_dir,\"valid\", label])\n",
    "            shutil.copy(os.path.join(data_dir, train_data,train_file), os.path.join(data_dir, input_dir,\"valid\", label))\n",
    "            copy_dict[label] = copy_dict.get(label,0)+1\n",
    "            #if I use copy_dict[label]+=1, get bedlington_terrier\n",
    "        else:\n",
    "            mkdir_if_not_exist([data_dir, input_dir,\"train\", label])\n",
    "            shutil.copy(os.path.join(data_dir, train_data,train_file), os.path.join(data_dir, input_dir,\"train\", label))\n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_data)):\n",
    "        mkdir_if_not_exist([data_dir, input_dir, \"test\", \"unknow\"])\n",
    "        shutil.copy(os.path.join(data_dir, test_data,test_file), os.path.join(data_dir, input_dir,\"test\", \"unknow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if demo:\n",
    "    input_dir, batch_size = \"train_valid_test_tiny\", 1\n",
    "else:\n",
    "    input_dir, train_data, test_data, label_file= \"input_dir\", \"train\",\"test\",\"labels.csv\"\n",
    "    batch_size,valid_rate =128, 0.1\n",
    "    regor_dog_data(data_dir,train_data,test_data,label_file,input_dir,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = gdata.vision.transforms.Compose([\n",
    "    # 随机对图像裁剪出面积为原图像面积 0.08 到 1 倍之间、且高和宽之比在 3/4 和 4/3 之间\n",
    "    # 的图像，再放缩为高和宽均为 224 像素的新图像。\n",
    "    gdata.vision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n",
    "                                              ratio=(3.0/4.0, 4.0/3.0)),\n",
    "    # 随机左右翻转图像。\n",
    "    gdata.vision.transforms.RandomFlipLeftRight(),\n",
    "    # 随机抖动亮度、对比度和饱和度。\n",
    "    gdata.vision.transforms.RandomColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                              saturation=0.4),\n",
    "    # 随机加噪音。\n",
    "    gdata.vision.transforms.RandomLighting(0.1),\n",
    "    \n",
    "    # 将图像像素值按比例缩小到 0 和 1 之间，并将数据格式从“高 * 宽 * 通道”改为\n",
    "    # “通道 * 高 * 宽”。\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    # 对图像的每个通道做标准化。\n",
    "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                      [0.229, 0.224, 0.225])])\n",
    "\n",
    "# 测试时，只使用确定性的图像预处理操作。\n",
    "transform_test = gdata.vision.transforms.Compose([\n",
    "    gdata.vision.transforms.Resize(256),\n",
    "    # 将图像中央的高和宽均为 224 的正方形区域裁剪出来。\n",
    "    gdata.vision.transforms.CenterCrop(224),\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                      [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir,input_dir,\"train\"), flag=1)\n",
    "valid_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir,input_dir,\"valid\"), flag=1)\n",
    "train_valid_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir,input_dir,\"train_valid\"), flag=1)\n",
    "test_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir,input_dir,\"test\"), flag=1)\n",
    "\n",
    "train_data=gdata.DataLoader(train_ds.transform_first(transform_train), batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data=gdata.DataLoader(valid_ds.transform_first(transform_train), batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data=gdata.DataLoader(train_valid_ds.transform_first(transform_train), batch_size, shuffle=True, last_batch='keep')\n",
    "test_data=gdata.DataLoader(test_ds.transform_first(transform_test), batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(ctx):\n",
    "    finetune_net= model_zoo.vision.resnet34_v2(pretrained=True)\n",
    "    finetune_net.output_new = nn.HybridSequential(prefix=\"\")\n",
    "    finetune_net.output_new.add(nn.Dense(256, activation='relu'))\n",
    "    finetune_net.output_new.add(nn.Dense(120))\n",
    "    finetune_net.output_new.initialize(init.Xavier(), ctx=ctx)\n",
    "    # need to put the parameters on to model cpu or gpu()\n",
    "    finetune_net.collect_params().reset_ctx(ctx)\n",
    "    return finetune_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If sparse_label is True (default), label should contain integer category indicators:\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Use the get_loss to get the loss for the valid data, can not use the net(X) directly because we will not use the\n",
    "# old output layer\n",
    "def get_loss(data, net, ctx):\n",
    "    l=0\n",
    "    for X, y in data:\n",
    "        features_out = net.features(X.as_in_context(ctx))\n",
    "        output=net.output_new(features_out)\n",
    "        l += loss(output, y.as_in_context(ctx)).mean().asscalar()\n",
    "    return l/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data, valid_data, lr, wd, num_epochs, lr_decay,lr_period, batch_size, ctx):\n",
    "    trainer = gluon.Trainer(net.output_new.collect_params(),'sgd', {'learning_rate':lr, 'momentum':0.9, 'wd': wd})\n",
    "    previous_time=datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l = 0\n",
    "        if epoch > 0 and epoch%lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
    "        for X, y in train_data:\n",
    "            features_out = net.features(X.as_in_context(ctx))\n",
    "            with autograd.record():\n",
    "                output = net.output_new(features_out)\n",
    "                #l = loss(output,y.astype('float32').as_in_context(ctx))\n",
    "                l = loss(output,y.as_in_context(ctx))\n",
    "\n",
    "            l.backward()\n",
    "            #print(l)\n",
    "            train_l += l.mean().asscalar()\n",
    "            trainer.step(batch_size)\n",
    "            \n",
    "        current_time=datetime.datetime.now()\n",
    "        \n",
    "        h,reminder=divmod((current_time-previous_time).seconds, 3600)\n",
    "        m,s = divmod(reminder, 60)\n",
    "        time_s = \"time: %02d:%02d:%02d\" %(h,m,s)\n",
    "        \n",
    "        #print(train_l)\n",
    "        if epoch % 1 == 0:\n",
    "            if valid_data is not None:  \n",
    "                print(\"epoch %d, train_loss %f, valid_loss %f, learning_rate %f, time %s\"%\n",
    "                      (epoch, train_l/len(train_data), get_loss(valid_data, net, ctx), \n",
    "                      trainer.learning_rate, time_s))\n",
    "            else:\n",
    "                print(\"epoch %d, train_loss %f, learning_rate %f, time %s\"%\n",
    "                      (epoch, train_l/len(train_data),trainer.learning_rate,time_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train_loss 0.708829, valid_loss 0.969698, learning_rate 0.000100, time time: 00:01:18\n",
      "epoch 1, train_loss 0.691222, valid_loss 0.847319, learning_rate 0.000100, time time: 00:02:42\n",
      "epoch 2, train_loss 0.685034, valid_loss 0.840691, learning_rate 0.000100, time time: 00:04:06\n",
      "epoch 3, train_loss 0.704227, valid_loss 0.820492, learning_rate 0.000100, time time: 00:05:31\n",
      "epoch 4, train_loss 0.704574, valid_loss 0.763563, learning_rate 0.000100, time time: 00:06:55\n",
      "epoch 5, train_loss 0.704703, valid_loss 0.892400, learning_rate 0.000100, time time: 00:08:19\n",
      "epoch 6, train_loss 0.663265, valid_loss 0.865297, learning_rate 0.000100, time time: 00:09:44\n",
      "epoch 7, train_loss 0.707593, valid_loss 0.918001, learning_rate 0.000100, time time: 00:11:08\n",
      "epoch 8, train_loss 0.676576, valid_loss 0.792126, learning_rate 0.000100, time time: 00:12:32\n",
      "epoch 9, train_loss 0.701074, valid_loss 0.829652, learning_rate 0.000100, time time: 00:13:56\n",
      "epoch 10, train_loss 0.661341, valid_loss 0.896218, learning_rate 0.000010, time time: 00:15:20\n",
      "epoch 11, train_loss 0.688143, valid_loss 0.836062, learning_rate 0.000010, time time: 00:16:45\n",
      "epoch 12, train_loss 0.698715, valid_loss 0.795304, learning_rate 0.000010, time time: 00:18:09\n",
      "epoch 13, train_loss 0.688091, valid_loss 0.890021, learning_rate 0.000010, time time: 00:19:33\n",
      "epoch 14, train_loss 0.689314, valid_loss 0.999812, learning_rate 0.000010, time time: 00:20:57\n",
      "epoch 15, train_loss 0.694754, valid_loss 0.822169, learning_rate 0.000010, time time: 00:22:21\n",
      "epoch 16, train_loss 0.675155, valid_loss 0.907007, learning_rate 0.000010, time time: 00:23:45\n",
      "epoch 17, train_loss 0.706921, valid_loss 0.871690, learning_rate 0.000010, time time: 00:25:09\n",
      "epoch 18, train_loss 0.672578, valid_loss 0.936562, learning_rate 0.000010, time time: 00:26:33\n",
      "epoch 19, train_loss 0.690194, valid_loss 0.961497, learning_rate 0.000010, time time: 00:27:58\n",
      "epoch 20, train_loss 0.681438, valid_loss 0.823333, learning_rate 0.000001, time time: 00:29:22\n",
      "epoch 21, train_loss 0.676868, valid_loss 0.859345, learning_rate 0.000001, time time: 00:30:46\n",
      "epoch 22, train_loss 0.707462, valid_loss 0.923440, learning_rate 0.000001, time time: 00:32:10\n",
      "epoch 23, train_loss 0.689449, valid_loss 0.960155, learning_rate 0.000001, time time: 00:33:34\n",
      "epoch 24, train_loss 0.681052, valid_loss 0.877784, learning_rate 0.000001, time time: 00:34:58\n",
      "epoch 25, train_loss 0.700997, valid_loss 0.867561, learning_rate 0.000001, time time: 00:36:22\n",
      "epoch 26, train_loss 0.681117, valid_loss 0.925294, learning_rate 0.000001, time time: 00:37:47\n",
      "epoch 27, train_loss 0.690105, valid_loss 0.890306, learning_rate 0.000001, time time: 00:39:11\n",
      "epoch 28, train_loss 0.692771, valid_loss 0.852152, learning_rate 0.000001, time time: 00:40:35\n",
      "epoch 29, train_loss 0.706123, valid_loss 0.909249, learning_rate 0.000001, time time: 00:41:59\n",
      "epoch 30, train_loss 0.679535, valid_loss 0.854591, learning_rate 0.000000, time time: 00:43:24\n",
      "epoch 31, train_loss 0.699731, valid_loss 0.853516, learning_rate 0.000000, time time: 00:44:48\n",
      "epoch 32, train_loss 0.683030, valid_loss 0.903656, learning_rate 0.000000, time time: 00:46:12\n",
      "epoch 33, train_loss 0.686695, valid_loss 0.872952, learning_rate 0.000000, time time: 00:47:36\n",
      "epoch 34, train_loss 0.678439, valid_loss 0.879348, learning_rate 0.000000, time time: 00:49:00\n",
      "epoch 35, train_loss 0.680621, valid_loss 1.002466, learning_rate 0.000000, time time: 00:50:24\n",
      "epoch 36, train_loss 0.678050, valid_loss 0.934589, learning_rate 0.000000, time time: 00:51:48\n",
      "epoch 37, train_loss 0.676393, valid_loss 0.826187, learning_rate 0.000000, time time: 00:53:13\n",
      "epoch 38, train_loss 0.685758, valid_loss 0.910204, learning_rate 0.000000, time time: 00:54:37\n",
      "epoch 39, train_loss 0.674833, valid_loss 0.931265, learning_rate 0.000000, time time: 00:56:01\n",
      "epoch 40, train_loss 0.688909, valid_loss 0.836148, learning_rate 0.000000, time time: 00:57:25\n",
      "epoch 41, train_loss 0.703630, valid_loss 0.846586, learning_rate 0.000000, time time: 00:58:49\n",
      "epoch 42, train_loss 0.689304, valid_loss 0.993433, learning_rate 0.000000, time time: 01:00:13\n",
      "epoch 43, train_loss 0.676347, valid_loss 0.886146, learning_rate 0.000000, time time: 01:01:37\n",
      "epoch 44, train_loss 0.687546, valid_loss 0.932399, learning_rate 0.000000, time time: 01:03:01\n",
      "epoch 45, train_loss 0.681229, valid_loss 0.859654, learning_rate 0.000000, time time: 01:04:25\n",
      "epoch 46, train_loss 0.679235, valid_loss 0.837178, learning_rate 0.000000, time time: 01:05:50\n",
      "epoch 47, train_loss 0.674072, valid_loss 0.859735, learning_rate 0.000000, time time: 01:07:14\n",
      "epoch 48, train_loss 0.688802, valid_loss 0.909849, learning_rate 0.000000, time time: 01:08:38\n",
      "epoch 49, train_loss 0.693971, valid_loss 0.899488, learning_rate 0.000000, time time: 01:10:02\n",
      "epoch 50, train_loss 0.699488, valid_loss 1.008742, learning_rate 0.000000, time time: 01:11:26\n",
      "epoch 51, train_loss 0.682057, valid_loss 0.882697, learning_rate 0.000000, time time: 01:12:50\n",
      "epoch 52, train_loss 0.695056, valid_loss 0.865336, learning_rate 0.000000, time time: 01:14:14\n",
      "epoch 53, train_loss 0.680656, valid_loss 0.864201, learning_rate 0.000000, time time: 01:15:38\n",
      "epoch 54, train_loss 0.708864, valid_loss 0.936354, learning_rate 0.000000, time time: 01:17:03\n",
      "epoch 55, train_loss 0.691257, valid_loss 0.887709, learning_rate 0.000000, time time: 01:18:27\n",
      "epoch 56, train_loss 0.680304, valid_loss 0.911382, learning_rate 0.000000, time time: 01:19:51\n"
     ]
    }
   ],
   "source": [
    "ctx, num_epochs, lr, wd = gb.try_gpu(), 100, 0.0001, 1e-4\n",
    "lr_period, lr_decay, net = 10, 0.1, get_net(ctx)\n",
    "net.hybridize()\n",
    "net.load_parameters(os.path.join(\"../../data/\", \"dog_2019_09_02_16_14.params\"))\n",
    "train(net, train_data, valid_data, lr, wd, num_epochs, \n",
    "      lr_decay, lr_period, batch_size, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\"../../data/\", \"dog_2019_09_02_night.params\")\n",
    "net.save_parameters(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
